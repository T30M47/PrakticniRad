"""from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("YourETLJob") \
    .config("spark.jars", "/app/postgresql-42.7.1.jar") \
    .getOrCreate()"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import format_number, regexp_replace
import psycopg2
from pyspark.sql.window import Window
from pyspark.sql import functions as F

def create_table(db_params, table_name, table_definition_sql):
    # Connect to PostgreSQL
    connection = psycopg2.connect(**db_params)
    cursor = connection.cursor()

    try:
        # Define the SQL statement to create the new table
        create_table_sql = f"""
            CREATE TABLE {table_name} {table_definition_sql}
        """

        # Execute the SQL statement to create the new table
        cursor.execute(create_table_sql)

        # Commit the changes
        connection.commit()

    finally:
        # Close the cursor and connection
        cursor.close()
        connection.close()

# PostgreSQL connection details
db_params = {
    "host": "prakticnirad_postgres_2_1",
    "port": 5432,
    "user": "postgres",
    "password": "Rea123Teo",
    "database": "warehouse"
}

# Define table definitions
proizvodi_definition = """
    (
        barkod_id INTEGER PRIMARY KEY,
        naziv_proizvoda VARCHAR(255) NOT NULL,
        cijena NUMERIC(10, 2) NOT NULL,
        proizvodjac VARCHAR(255),
        kategorija VARCHAR(255)
    )
"""

trgovine_definition = """
    (
        id_trgovine INTEGER PRIMARY KEY,
        naziv_trgovine VARCHAR(255) NOT NULL,
        lokacija VARCHAR(255) NOT NULL
    )
"""

transakcije_definition = """
    (
        id_transakcije INTEGER PRIMARY KEY,
        barkod_id INTEGER REFERENCES Proizvodi(barkod_id),
        id_trgovine INTEGER REFERENCES Trgovine(id_trgovine),
        kolicina INTEGER NOT NULL,
        ukupna_cijena DOUBLE PRECISION NOT NULL,
        datum_transakcije DATE NOT NULL,
        popust INTEGER NOT NULL
    )
"""

# Create tables
create_table(db_params, "Proizvodi", proizvodi_definition)
create_table(db_params, "Trgovine", trgovine_definition)
create_table(db_params, "Transakcije", transakcije_definition)

warehouse_url = "jdbc:postgresql://prakticnirad_postgres_2_1:5432/warehouse"

"""# PostgreSQL connection details
db_params = {
    "host": "prakticnirad_postgres_2_1",
    "port": 5432,
    "user": "postgres",
    "password": "Rea123Teo",
    "database": "warehouse"
}

# Connect to PostgreSQL
connection = psycopg2.connect(**db_params)
cursor = connection.cursor()

# Define the new table name
new_table_name = "Proizvodi"

# Define the SQL statement to create the new table
create_table_sql = f""""""
    CREATE TABLE {new_table_name} (
        barkod_id INTEGER PRIMARY KEY,
        naziv_proizvoda VARCHAR(255) NOT NULL,
        cijena NUMERIC(10, 2) NOT NULL,
        proizvodjac VARCHAR(255),
        kategorija VARCHAR(255)
    )
"""

"""# Execute the SQL statement to create the new table
cursor.execute(create_table_sql)

# Commit the changes
connection.commit()

# Close the cursor and connection
cursor.close()
connection.close()

# Connect to PostgreSQL
connection = psycopg2.connect(**db_params)
cursor = connection.cursor()

# Define the new table name
new_table_name = "Trgovine"

# Define the SQL statement to create the new table
create_table_sql = f""""""
    CREATE TABLE {new_table_name} (
        id_trgovine INTEGER PRIMARY KEY,
        naziv_trgovine VARCHAR(255) NOT NULL,
        lokacija VARCHAR(255) NOT NULL
    )
"""
"""
# Execute the SQL statement to create the new table
cursor.execute(create_table_sql)

# Commit the changes
connection.commit()

# Close the cursor and connection
cursor.close()
connection.close()

# Connect to PostgreSQL
connection = psycopg2.connect(**db_params)
cursor = connection.cursor()

# Define the new table name
new_table_name = "Transakcije"

# Define the SQL statement to create the new table
create_table_sql = f""""""
    CREATE TABLE {new_table_name} (
        id_transakcije INTEGER PRIMARY KEY,
        barkod_id INTEGER REFERENCES Proizvodi(barkod_id),
        id_trgovine INTEGER REFERENCES Trgovine(id_trgovine),
        kolicina INTEGER NOT NULL,
        ukupna_cijena DOUBLE PRECISION NOT NULL,
        datum_transakcije DATE NOT NULL,
        popust INTEGER NOT NULL
    )
"""
"""
# Execute the SQL statement to create the new table
cursor.execute(create_table_sql)

# Commit the changes
connection.commit()

# Close the cursor and connection
cursor.close()
connection.close()"""


# Step 1: Create SparkSession
spark = SparkSession.builder \
    .appName("Proizvodi") \
    .getOrCreate()


# Step 2: Configure PostgreSQL connection details
database_url = "jdbc:postgresql://prakticnirad_postgres_1:5432/transakcije"
database_properties = {
    "user": "postgres",
    "password": "Rea123Teo",
    "driver": "org.postgresql.Driver"
}

# Step 3: Load data from PostgreSQL
table_name = "Proizvodi"
df = spark.read.jdbc(url=database_url, table=table_name, properties=database_properties)

# Step 4: Transform Data - Format Price and Deduplicate
columns_to_check_duplicates = ["naziv_proizvoda", "cijena", "proizvodjac", "kategorija"]
df_transformed = df.dropDuplicates(subset=columns_to_check_duplicates)

# Create a window specification to partition by proizvodjac
#window_spec = Window().partitionBy("proizvodjac")

# Add "Co." to companies without "Co." based on the window
df_transformed = df_transformed.withColumn(
    "proizvodjac",
    F.when(F.col("proizvodjac").endswith("Co."), F.col("proizvodjac"))
    .otherwise(F.concat(F.col("proizvodjac"), F.lit(" Co.")))
)

#spark.sql(f"ALTER TABLE {new_table_name} ADD PRIMARY KEY (barkod_id)")

# Step 5: Write the transformed data to the new table in warehouse database
#warehouse_url = "jdbc:postgresql://prakticnirad_postgres_2_1:5432/warehouse"
df_transformed.write.jdbc(url=warehouse_url, table=table_name, mode="overwrite", properties=database_properties)

#df_transformed.write.jdbc(url=database_url, table=new_table_name, mode="overwrite", properties=database_properties)

# Step 6: Execute ETL Job
spark.stop()


# Step 1: Create SparkSession
spark = SparkSession.builder \
    .appName("Trgovine") \
    .getOrCreate()


# Step 2: Configure PostgreSQL connection details
database_url = "jdbc:postgresql://prakticnirad_postgres_1:5432/transakcije"
database_properties = {
    "user": "postgres",
    "password": "Rea123Teo",
    "driver": "org.postgresql.Driver"
}

# Step 3: Load data from PostgreSQL
table_name = "Trgovine"
df = spark.read.jdbc(url=database_url, table=table_name, properties=database_properties)

# Step 4: Transform Data - Format Price and Deduplicate
columns_to_check_duplicates = ["naziv_trgovine", "lokacija"]
df_transformed = df.dropDuplicates(subset=columns_to_check_duplicates)

#spark.sql(f"ALTER TABLE {new_table_name} ADD PRIMARY KEY (barkod_id)")

# Step 5: Write the transformed data to the new table in warehouse database
#warehouse_url = "jdbc:postgresql://prakticnirad_postgres_2_1:5432/warehouse"
df_transformed.write.jdbc(url=warehouse_url, table=table_name, mode="overwrite", properties=database_properties)

#df_transformed.write.jdbc(url=database_url, table=new_table_name, mode="overwrite", properties=database_properties)

# Step 6: Execute ETL Job
spark.stop()


# Step 1: Create SparkSession
spark = SparkSession.builder \
    .appName("Transakcije") \
    .getOrCreate()


# Step 2: Configure PostgreSQL connection details
database_url = "jdbc:postgresql://prakticnirad_postgres_1:5432/transakcije"
database_properties = {
    "user": "postgres",
    "password": "Rea123Teo",
    "driver": "org.postgresql.Driver"
}

# Step 3: Load data from PostgreSQL
table_name = "Transakcije"
df = spark.read.jdbc(url=database_url, table=table_name, properties=database_properties)

# Step 4: Transform Data - Format Price and Deduplicate
columns_to_check_duplicates = [
    "barkod_id",
    "id_trgovine",
    "kolicina",
    "ukupna_cijena",
    "datum_transakcije",
    "popust"
]

df_duplicates = df.dropDuplicates(subset=columns_to_check_duplicates)
df_transformed = df.withColumn("ukupna_cijena", format_number(df["ukupna_cijena"], 2))
df_transformed = df_transformed.withColumn("popust", regexp_replace("popust", "%", ""))
df_transformed = df_transformed.withColumn("popust", df_transformed["popust"].cast("integer"))

#spark.sql(f"ALTER TABLE {new_table_name} ADD PRIMARY KEY (barkod_id)")

# Step 5: Write the transformed data to the new table in warehouse database
#warehouse_url = "jdbc:postgresql://prakticnirad_postgres_2_1:5432/warehouse"
df_transformed.write.jdbc(url=warehouse_url, table=table_name, mode="overwrite", properties=database_properties)

#df_transformed.write.jdbc(url=database_url, table=new_table_name, mode="overwrite", properties=database_properties)

# Step 6: Execute ETL Job
spark.stop()